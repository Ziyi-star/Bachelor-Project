{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curb_scene</th>\n",
       "      <th>Acc-Z_1</th>\n",
       "      <th>Acc-Z_2</th>\n",
       "      <th>Acc-Z_3</th>\n",
       "      <th>Acc-Z_4</th>\n",
       "      <th>Acc-Z_5</th>\n",
       "      <th>Acc-Z_6</th>\n",
       "      <th>Acc-Z_7</th>\n",
       "      <th>Acc-Z_8</th>\n",
       "      <th>Acc-Z_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Acc-Z_91</th>\n",
       "      <th>Acc-Z_92</th>\n",
       "      <th>Acc-Z_93</th>\n",
       "      <th>Acc-Z_94</th>\n",
       "      <th>Acc-Z_95</th>\n",
       "      <th>Acc-Z_96</th>\n",
       "      <th>Acc-Z_97</th>\n",
       "      <th>Acc-Z_98</th>\n",
       "      <th>Acc-Z_99</th>\n",
       "      <th>Acc-Z_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.753204</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.753204</td>\n",
       "      <td>8.748413</td>\n",
       "      <td>8.738831</td>\n",
       "      <td>8.748413</td>\n",
       "      <td>8.743622</td>\n",
       "      <td>...</td>\n",
       "      <td>8.786728</td>\n",
       "      <td>8.801086</td>\n",
       "      <td>8.820236</td>\n",
       "      <td>8.786728</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>8.772354</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.801086</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.753204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.748413</td>\n",
       "      <td>8.767563</td>\n",
       "      <td>8.729263</td>\n",
       "      <td>8.695740</td>\n",
       "      <td>8.724472</td>\n",
       "      <td>8.767563</td>\n",
       "      <td>8.767563</td>\n",
       "      <td>...</td>\n",
       "      <td>8.753204</td>\n",
       "      <td>8.772354</td>\n",
       "      <td>8.786728</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.786728</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>8.738831</td>\n",
       "      <td>8.820236</td>\n",
       "      <td>8.738831</td>\n",
       "      <td>8.757996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.796295</td>\n",
       "      <td>8.772354</td>\n",
       "      <td>8.772354</td>\n",
       "      <td>8.772354</td>\n",
       "      <td>8.786728</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.801086</td>\n",
       "      <td>8.767563</td>\n",
       "      <td>...</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>8.753204</td>\n",
       "      <td>8.767563</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.753204</td>\n",
       "      <td>8.748413</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.772354</td>\n",
       "      <td>8.767563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.753204</td>\n",
       "      <td>8.801086</td>\n",
       "      <td>8.753204</td>\n",
       "      <td>8.829819</td>\n",
       "      <td>8.753204</td>\n",
       "      <td>8.786728</td>\n",
       "      <td>8.815445</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>...</td>\n",
       "      <td>8.805878</td>\n",
       "      <td>8.796295</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.801086</td>\n",
       "      <td>8.810669</td>\n",
       "      <td>8.796295</td>\n",
       "      <td>8.805878</td>\n",
       "      <td>8.791504</td>\n",
       "      <td>8.791504</td>\n",
       "      <td>8.772354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.757996</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>8.767563</td>\n",
       "      <td>8.786728</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>8.753204</td>\n",
       "      <td>8.757996</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>...</td>\n",
       "      <td>8.757996</td>\n",
       "      <td>8.757996</td>\n",
       "      <td>8.772354</td>\n",
       "      <td>8.767563</td>\n",
       "      <td>8.757996</td>\n",
       "      <td>8.743622</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>8.743622</td>\n",
       "      <td>8.786728</td>\n",
       "      <td>8.796295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9312</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.575378</td>\n",
       "      <td>5.295975</td>\n",
       "      <td>5.295975</td>\n",
       "      <td>16.682800</td>\n",
       "      <td>19.517532</td>\n",
       "      <td>14.781799</td>\n",
       "      <td>14.609421</td>\n",
       "      <td>7.469910</td>\n",
       "      <td>11.252747</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.689407</td>\n",
       "      <td>2.274490</td>\n",
       "      <td>4.649536</td>\n",
       "      <td>-18.933350</td>\n",
       "      <td>-24.708160</td>\n",
       "      <td>-21.212631</td>\n",
       "      <td>-3.002335</td>\n",
       "      <td>10.764328</td>\n",
       "      <td>19.019547</td>\n",
       "      <td>19.871872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9313</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100555</td>\n",
       "      <td>-6.871353</td>\n",
       "      <td>3.026276</td>\n",
       "      <td>17.348389</td>\n",
       "      <td>15.734695</td>\n",
       "      <td>13.632584</td>\n",
       "      <td>13.632584</td>\n",
       "      <td>14.556747</td>\n",
       "      <td>12.014099</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.385788</td>\n",
       "      <td>-30.980972</td>\n",
       "      <td>-23.218964</td>\n",
       "      <td>-6.301544</td>\n",
       "      <td>14.973343</td>\n",
       "      <td>18.669983</td>\n",
       "      <td>26.542114</td>\n",
       "      <td>38.690308</td>\n",
       "      <td>48.295837</td>\n",
       "      <td>53.400284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9314</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.004654</td>\n",
       "      <td>9.461884</td>\n",
       "      <td>15.811310</td>\n",
       "      <td>22.572540</td>\n",
       "      <td>20.719421</td>\n",
       "      <td>20.719421</td>\n",
       "      <td>7.910446</td>\n",
       "      <td>0.928955</td>\n",
       "      <td>-0.574615</td>\n",
       "      <td>...</td>\n",
       "      <td>4.922485</td>\n",
       "      <td>19.182343</td>\n",
       "      <td>20.283676</td>\n",
       "      <td>20.283676</td>\n",
       "      <td>12.129028</td>\n",
       "      <td>-3.567368</td>\n",
       "      <td>-3.567368</td>\n",
       "      <td>1.077393</td>\n",
       "      <td>9.370911</td>\n",
       "      <td>10.749970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9315</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60.429657</td>\n",
       "      <td>25.072083</td>\n",
       "      <td>9.495407</td>\n",
       "      <td>-14.068329</td>\n",
       "      <td>-19.512741</td>\n",
       "      <td>-11.065994</td>\n",
       "      <td>2.049438</td>\n",
       "      <td>2.049438</td>\n",
       "      <td>10.376465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210693</td>\n",
       "      <td>0.804459</td>\n",
       "      <td>0.804459</td>\n",
       "      <td>11.267120</td>\n",
       "      <td>10.807434</td>\n",
       "      <td>8.063675</td>\n",
       "      <td>4.228165</td>\n",
       "      <td>4.505890</td>\n",
       "      <td>19.072205</td>\n",
       "      <td>19.072205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9316</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.104431</td>\n",
       "      <td>0.574615</td>\n",
       "      <td>9.016571</td>\n",
       "      <td>19.579788</td>\n",
       "      <td>11.305420</td>\n",
       "      <td>11.305420</td>\n",
       "      <td>-5.975922</td>\n",
       "      <td>-22.026657</td>\n",
       "      <td>-15.983688</td>\n",
       "      <td>...</td>\n",
       "      <td>13.651733</td>\n",
       "      <td>18.195938</td>\n",
       "      <td>18.195938</td>\n",
       "      <td>20.264526</td>\n",
       "      <td>19.364304</td>\n",
       "      <td>13.091492</td>\n",
       "      <td>13.627792</td>\n",
       "      <td>-0.177170</td>\n",
       "      <td>-3.438080</td>\n",
       "      <td>-2.365479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9317 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      curb_scene    Acc-Z_1    Acc-Z_2    Acc-Z_3    Acc-Z_4    Acc-Z_5  \\\n",
       "0            0.0   8.762772   8.753204   8.762772   8.781937   8.753204   \n",
       "1            0.0   8.762772   8.762772   8.748413   8.767563   8.729263   \n",
       "2            0.0   8.781937   8.796295   8.772354   8.772354   8.772354   \n",
       "3            0.0   8.781937   8.753204   8.801086   8.753204   8.829819   \n",
       "4            0.0   8.757996   8.762772   8.777145   8.767563   8.786728   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "9312         1.0  -1.575378   5.295975   5.295975  16.682800  19.517532   \n",
       "9313         1.0   0.100555  -6.871353   3.026276  17.348389  15.734695   \n",
       "9314         1.0   6.004654   9.461884  15.811310  22.572540  20.719421   \n",
       "9315         1.0  60.429657  25.072083   9.495407 -14.068329 -19.512741   \n",
       "9316         1.0   5.104431   0.574615   9.016571  19.579788  11.305420   \n",
       "\n",
       "        Acc-Z_6    Acc-Z_7    Acc-Z_8    Acc-Z_9  ...   Acc-Z_91   Acc-Z_92  \\\n",
       "0      8.748413   8.738831   8.748413   8.743622  ...   8.786728   8.801086   \n",
       "1      8.695740   8.724472   8.767563   8.767563  ...   8.753204   8.772354   \n",
       "2      8.786728   8.781937   8.801086   8.767563  ...   8.777145   8.753204   \n",
       "3      8.753204   8.786728   8.815445   8.762772  ...   8.805878   8.796295   \n",
       "4      8.777145   8.753204   8.757996   8.777145  ...   8.757996   8.757996   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "9312  14.781799  14.609421   7.469910  11.252747  ...  -6.689407   2.274490   \n",
       "9313  13.632584  13.632584  14.556747  12.014099  ... -22.385788 -30.980972   \n",
       "9314  20.719421   7.910446   0.928955  -0.574615  ...   4.922485  19.182343   \n",
       "9315 -11.065994   2.049438   2.049438  10.376465  ...   0.210693   0.804459   \n",
       "9316  11.305420  -5.975922 -22.026657 -15.983688  ...  13.651733  18.195938   \n",
       "\n",
       "       Acc-Z_93   Acc-Z_94   Acc-Z_95   Acc-Z_96   Acc-Z_97   Acc-Z_98  \\\n",
       "0      8.820236   8.786728   8.777145   8.772354   8.781937   8.801086   \n",
       "1      8.786728   8.781937   8.786728   8.777145   8.738831   8.820236   \n",
       "2      8.767563   8.762772   8.762772   8.753204   8.748413   8.762772   \n",
       "3      8.781937   8.801086   8.810669   8.796295   8.805878   8.791504   \n",
       "4      8.772354   8.767563   8.757996   8.743622   8.777145   8.743622   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "9312   4.649536 -18.933350 -24.708160 -21.212631  -3.002335  10.764328   \n",
       "9313 -23.218964  -6.301544  14.973343  18.669983  26.542114  38.690308   \n",
       "9314  20.283676  20.283676  12.129028  -3.567368  -3.567368   1.077393   \n",
       "9315   0.804459  11.267120  10.807434   8.063675   4.228165   4.505890   \n",
       "9316  18.195938  20.264526  19.364304  13.091492  13.627792  -0.177170   \n",
       "\n",
       "       Acc-Z_99  Acc-Z_100  \n",
       "0      8.781937   8.753204  \n",
       "1      8.738831   8.757996  \n",
       "2      8.772354   8.767563  \n",
       "3      8.791504   8.772354  \n",
       "4      8.786728   8.796295  \n",
       "...         ...        ...  \n",
       "9312  19.019547  19.871872  \n",
       "9313  48.295837  53.400284  \n",
       "9314   9.370911  10.749970  \n",
       "9315  19.072205  19.072205  \n",
       "9316  -3.438080  -2.365479  \n",
       "\n",
       "[9317 rows x 101 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For vscode\n",
    "import pandas as pd #reading dataset\n",
    "import matplotlib as mpl    #plotting, visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf #building model\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np  #playing output with model\n",
    "from sklearn.model_selection import train_test_split    #model selection and scaling data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../')   # Add parent directory to Python path\n",
    "from utils.Plots import *\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "df = pd.read_csv('../../../data/handlebar/processed_segments_overlap_50.csv') \n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m RANDOM_SEED \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m     15\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/Project/data/processed_segments_overlap_50.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# For Colab\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import dates as md\n",
    "from sklearn.model_selection import train_test_split    #model selection and scaling data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "df = pd.read_csv('/content/drive/MyDrive/Project/data/processed_segments_overlap_50.csv')\n",
    "#df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "# # 0 for normal, 1 for abnormal\n",
    "df['curb_scene'].value_counts()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose df is your DataFrame, and df['curb_scene'] is your label column\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(df, df['curb_scene'], \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=RANDOM_SEED)\n",
    "                                                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling data, because neural network works better with scaled data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit(train_data.iloc[:, 3:])\n",
    "#transform data\n",
    "train_data_scaled = scaler.transform(train_data.iloc[:, 3:])\n",
    "test_data_scaled = scaler.transform(test_data.iloc[:, 3:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the scaled data back to DataFrames for further processing\n",
    "train_data_scaled_df = pd.DataFrame(train_data_scaled, columns=train_data.columns[3:])\n",
    "test_data_scaled_df = pd.DataFrame(test_data_scaled, columns=test_data.columns[3:])\n",
    "# Add the 'curb_scene', 'start_time', and 'end_time' columns back to the scaled DataFrames\n",
    "train_data_scaled_df['curb_scene'] = train_data['curb_scene'].values\n",
    "test_data_scaled_df['curb_scene'] = test_data['curb_scene'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([   0,    1,    2,    3,    4,    5,    6,    8,    9,   10,\n",
      "       ...\n",
      "       1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863],\n",
      "      dtype='int64', length=1796)\n",
      "Index([   7,   54,   63,   73,   92,   94,  119,  188,  204,  209,  218,  330,\n",
      "        358,  363,  402,  412,  421,  456,  530,  553,  567,  584,  590,  597,\n",
      "        757,  784,  796,  840,  891,  894,  949,  950,  955,  962,  978,  979,\n",
      "        990, 1006, 1033, 1038, 1071, 1126, 1135, 1143, 1168, 1195, 1266, 1272,\n",
      "       1274, 1275, 1279, 1359, 1384, 1399, 1409, 1442, 1462, 1472, 1520, 1521,\n",
      "       1562, 1581, 1598, 1624, 1628, 1655, 1673, 1763],\n",
      "      dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Filter and slice the data\n",
    "normal_train_data_scaled = train_data_scaled_df[train_data_scaled_df['curb_scene'] == 0.0].iloc[:, :-3]\n",
    "abnormal_train_data_scaled = train_data_scaled_df[train_data_scaled_df['curb_scene'] == 1.0].iloc[:, :-3]\n",
    "normal_test_data_scaled = test_data_scaled_df[test_data_scaled_df['curb_scene'] == 0.0].iloc[:, :-3]\n",
    "abnormal_test_data_scaled = test_data_scaled_df[test_data_scaled_df['curb_scene'] == 1.0].iloc[:, :-3]\n",
    "# Example usage: Accessing the original index\n",
    "print(normal_test_data_scaled.index)\n",
    "print(abnormal_test_data_scaled.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float32\n",
    "normal_train_data_scaled = normal_train_data_scaled.astype(\"float32\")\n",
    "abnormal_train_data_scaled = abnormal_train_data_scaled.astype(\"float32\")\n",
    "normal_test_data_scaled = normal_test_data_scaled.astype(\"float32\")\n",
    "abnormal_test_data_scaled = abnormal_test_data_scaled.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import keras_tuner as kt\n",
    "\n",
    "class AutoEncoder(Model):\n",
    "    def __init__(self, hp):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = tf.keras.Sequential()\n",
    "        for i in range(hp.Int('num_encoder_layers', 1, 3)):\n",
    "            self.encoder.add(Dense(units=hp.Int(f'units_encoder_{i}', min_value=32, max_value=128, step=32), activation='tanh'))\n",
    "            self.encoder.add(Dropout(rate=hp.Float(f'dropout_encoder_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = tf.keras.Sequential()\n",
    "        for i in range(hp.Int('num_decoder_layers', 1, 3)):\n",
    "            self.decoder.add(Dense(units=hp.Int(f'units_decoder_{i}', min_value=32, max_value=128, step=32), activation='tanh'))\n",
    "            self.decoder.add(Dropout(rate=hp.Float(f'dropout_decoder_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "        \n",
    "        # Output layer\n",
    "        self.decoder.add(Dense(100, activation='tanh'))\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = AutoEncoder(hp)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\autoencoder_tuning\\tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 13\n",
      "num_encoder_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "units_encoder_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "dropout_encoder_0 (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "num_decoder_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "units_decoder_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "dropout_decoder_0 (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "units_encoder_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "dropout_encoder_1 (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "units_decoder_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "dropout_decoder_1 (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "units_encoder_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "dropout_encoder_2 (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Define the tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel = build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=3,  # Number of different hyperparameter combinations to try\n",
    "    executions_per_trial=2,  # Number of models to build and fit for each trial\n",
    "    directory='my_dir',\n",
    "    project_name='autoencoder_tuning'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the search\n",
    "tuner.search(\n",
    "    normal_train_data_scaled, \n",
    "    normal_train_data_scaled,\n",
    "    epochs=100,\n",
    "    validation_split=0.3,\n",
    "    batch_size=kt.HyperParameters().Int('batch_size', min_value=32, max_value=512, step=32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of encoder layers is 3.\n",
      "The optimal number of units in each encoder layer are [32, 64, 32].\n",
      "The optimal dropout rates for each encoder layer are [0.30000000000000004, 0.2, 0.1].\n",
      "The optimal number of decoder layers is 1.\n",
      "The optimal number of units in each decoder layer are [128].\n",
      "The optimal dropout rates for each decoder layer are [0.30000000000000004].\n",
      "The optimal learning rate is 0.0006621908905224919.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\")\n",
    "for key, value in best_hps.values.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
