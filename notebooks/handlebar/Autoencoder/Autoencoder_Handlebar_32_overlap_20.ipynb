{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #reading dataset\n",
    "import matplotlib as mpl    #plotting, visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf #building model\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np  #playing output with model\n",
    "from sklearn.model_selection import train_test_split    #model selection and scaling data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')   # Add parent directory to Python path\n",
    "from utils.Plots import *\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curb_scene</th>\n",
       "      <th>Acc-Z_1</th>\n",
       "      <th>Acc-Z_2</th>\n",
       "      <th>Acc-Z_3</th>\n",
       "      <th>Acc-Z_4</th>\n",
       "      <th>Acc-Z_5</th>\n",
       "      <th>Acc-Z_6</th>\n",
       "      <th>Acc-Z_7</th>\n",
       "      <th>Acc-Z_8</th>\n",
       "      <th>Acc-Z_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Acc-Z_91</th>\n",
       "      <th>Acc-Z_92</th>\n",
       "      <th>Acc-Z_93</th>\n",
       "      <th>Acc-Z_94</th>\n",
       "      <th>Acc-Z_95</th>\n",
       "      <th>Acc-Z_96</th>\n",
       "      <th>Acc-Z_97</th>\n",
       "      <th>Acc-Z_98</th>\n",
       "      <th>Acc-Z_99</th>\n",
       "      <th>Acc-Z_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.753204</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.753204</td>\n",
       "      <td>8.748413</td>\n",
       "      <td>8.738831</td>\n",
       "      <td>8.748413</td>\n",
       "      <td>8.743622</td>\n",
       "      <td>...</td>\n",
       "      <td>8.786728</td>\n",
       "      <td>8.801086</td>\n",
       "      <td>8.820236</td>\n",
       "      <td>8.786728</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>8.772354</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.801086</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.753204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.757996</td>\n",
       "      <td>8.801086</td>\n",
       "      <td>8.815445</td>\n",
       "      <td>8.796295</td>\n",
       "      <td>8.791504</td>\n",
       "      <td>8.796295</td>\n",
       "      <td>8.805878</td>\n",
       "      <td>8.801086</td>\n",
       "      <td>8.801086</td>\n",
       "      <td>...</td>\n",
       "      <td>8.772354</td>\n",
       "      <td>8.757996</td>\n",
       "      <td>8.791504</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.753204</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>8.810669</td>\n",
       "      <td>8.767563</td>\n",
       "      <td>8.815445</td>\n",
       "      <td>8.781937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.767563</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>8.748413</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.805878</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>...</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>8.767563</td>\n",
       "      <td>8.772354</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>8.796295</td>\n",
       "      <td>8.801086</td>\n",
       "      <td>8.805878</td>\n",
       "      <td>8.772354</td>\n",
       "      <td>8.796295</td>\n",
       "      <td>8.805878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.805878</td>\n",
       "      <td>8.796295</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.801086</td>\n",
       "      <td>8.810669</td>\n",
       "      <td>8.796295</td>\n",
       "      <td>8.805878</td>\n",
       "      <td>8.791504</td>\n",
       "      <td>8.791504</td>\n",
       "      <td>...</td>\n",
       "      <td>8.748413</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>8.767563</td>\n",
       "      <td>8.757996</td>\n",
       "      <td>8.757996</td>\n",
       "      <td>8.757996</td>\n",
       "      <td>8.767563</td>\n",
       "      <td>8.791504</td>\n",
       "      <td>8.786728</td>\n",
       "      <td>8.786728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.753204</td>\n",
       "      <td>8.777145</td>\n",
       "      <td>8.767563</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.786728</td>\n",
       "      <td>8.734055</td>\n",
       "      <td>8.786728</td>\n",
       "      <td>8.753204</td>\n",
       "      <td>8.786728</td>\n",
       "      <td>...</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.805878</td>\n",
       "      <td>8.781937</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.757996</td>\n",
       "      <td>8.762772</td>\n",
       "      <td>8.767563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5819</th>\n",
       "      <td>1.0</td>\n",
       "      <td>34.648895</td>\n",
       "      <td>23.879776</td>\n",
       "      <td>15.988480</td>\n",
       "      <td>6.268021</td>\n",
       "      <td>10.884048</td>\n",
       "      <td>19.613297</td>\n",
       "      <td>-0.957687</td>\n",
       "      <td>-21.456833</td>\n",
       "      <td>-36.889862</td>\n",
       "      <td>...</td>\n",
       "      <td>15.940598</td>\n",
       "      <td>18.382675</td>\n",
       "      <td>11.247955</td>\n",
       "      <td>3.294418</td>\n",
       "      <td>-5.956772</td>\n",
       "      <td>-6.038177</td>\n",
       "      <td>11.578354</td>\n",
       "      <td>21.950043</td>\n",
       "      <td>22.313965</td>\n",
       "      <td>7.627930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5820</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.601776</td>\n",
       "      <td>51.753067</td>\n",
       "      <td>54.276550</td>\n",
       "      <td>25.996246</td>\n",
       "      <td>-2.097321</td>\n",
       "      <td>-2.097321</td>\n",
       "      <td>-10.553635</td>\n",
       "      <td>-1.010361</td>\n",
       "      <td>7.383713</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019150</td>\n",
       "      <td>0.584183</td>\n",
       "      <td>-6.746857</td>\n",
       "      <td>-2.638412</td>\n",
       "      <td>9.390060</td>\n",
       "      <td>6.876144</td>\n",
       "      <td>15.078690</td>\n",
       "      <td>15.078690</td>\n",
       "      <td>7.762009</td>\n",
       "      <td>10.433929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.561401</td>\n",
       "      <td>15.883133</td>\n",
       "      <td>15.883133</td>\n",
       "      <td>11.774689</td>\n",
       "      <td>13.302185</td>\n",
       "      <td>10.544067</td>\n",
       "      <td>17.769760</td>\n",
       "      <td>16.610977</td>\n",
       "      <td>13.584702</td>\n",
       "      <td>...</td>\n",
       "      <td>60.429657</td>\n",
       "      <td>25.072083</td>\n",
       "      <td>9.495407</td>\n",
       "      <td>-14.068329</td>\n",
       "      <td>-19.512741</td>\n",
       "      <td>-11.065994</td>\n",
       "      <td>2.049438</td>\n",
       "      <td>2.049438</td>\n",
       "      <td>10.376465</td>\n",
       "      <td>13.273453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-22.385788</td>\n",
       "      <td>-30.980972</td>\n",
       "      <td>-23.218964</td>\n",
       "      <td>-6.301544</td>\n",
       "      <td>14.973343</td>\n",
       "      <td>18.669983</td>\n",
       "      <td>26.542114</td>\n",
       "      <td>38.690308</td>\n",
       "      <td>48.295837</td>\n",
       "      <td>...</td>\n",
       "      <td>27.562057</td>\n",
       "      <td>17.372330</td>\n",
       "      <td>11.903976</td>\n",
       "      <td>2.710236</td>\n",
       "      <td>5.200211</td>\n",
       "      <td>11.745956</td>\n",
       "      <td>5.736511</td>\n",
       "      <td>10.702087</td>\n",
       "      <td>2.834732</td>\n",
       "      <td>2.078171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.050079</td>\n",
       "      <td>28.208480</td>\n",
       "      <td>33.518830</td>\n",
       "      <td>33.518830</td>\n",
       "      <td>16.994050</td>\n",
       "      <td>5.975922</td>\n",
       "      <td>8.145081</td>\n",
       "      <td>6.023819</td>\n",
       "      <td>12.009323</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.142350</td>\n",
       "      <td>-7.795517</td>\n",
       "      <td>22.227768</td>\n",
       "      <td>39.446870</td>\n",
       "      <td>30.928299</td>\n",
       "      <td>7.326263</td>\n",
       "      <td>4.017471</td>\n",
       "      <td>16.634918</td>\n",
       "      <td>16.634918</td>\n",
       "      <td>20.034683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5824 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      curb_scene    Acc-Z_1    Acc-Z_2    Acc-Z_3    Acc-Z_4    Acc-Z_5  \\\n",
       "0            0.0   8.762772   8.753204   8.762772   8.781937   8.753204   \n",
       "1            0.0   8.757996   8.801086   8.815445   8.796295   8.791504   \n",
       "2            0.0   8.762772   8.767563   8.777145   8.777145   8.748413   \n",
       "3            0.0   8.805878   8.796295   8.781937   8.801086   8.810669   \n",
       "4            0.0   8.753204   8.777145   8.767563   8.762772   8.786728   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "5819         1.0  34.648895  23.879776  15.988480   6.268021  10.884048   \n",
       "5820         1.0  35.601776  51.753067  54.276550  25.996246  -2.097321   \n",
       "5821         1.0  20.561401  15.883133  15.883133  11.774689  13.302185   \n",
       "5822         1.0 -22.385788 -30.980972 -23.218964  -6.301544  14.973343   \n",
       "5823         1.0   9.050079  28.208480  33.518830  33.518830  16.994050   \n",
       "\n",
       "        Acc-Z_6    Acc-Z_7    Acc-Z_8    Acc-Z_9  ...   Acc-Z_91   Acc-Z_92  \\\n",
       "0      8.748413   8.738831   8.748413   8.743622  ...   8.786728   8.801086   \n",
       "1      8.796295   8.805878   8.801086   8.801086  ...   8.772354   8.757996   \n",
       "2      8.762772   8.805878   8.781937   8.777145  ...   8.777145   8.767563   \n",
       "3      8.796295   8.805878   8.791504   8.791504  ...   8.748413   8.777145   \n",
       "4      8.734055   8.786728   8.753204   8.786728  ...   8.762772   8.762772   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "5819  19.613297  -0.957687 -21.456833 -36.889862  ...  15.940598  18.382675   \n",
       "5820  -2.097321 -10.553635  -1.010361   7.383713  ...  -0.019150   0.584183   \n",
       "5821  10.544067  17.769760  16.610977  13.584702  ...  60.429657  25.072083   \n",
       "5822  18.669983  26.542114  38.690308  48.295837  ...  27.562057  17.372330   \n",
       "5823   5.975922   8.145081   6.023819  12.009323  ... -23.142350  -7.795517   \n",
       "\n",
       "       Acc-Z_93   Acc-Z_94   Acc-Z_95   Acc-Z_96   Acc-Z_97   Acc-Z_98  \\\n",
       "0      8.820236   8.786728   8.777145   8.772354   8.781937   8.801086   \n",
       "1      8.791504   8.781937   8.753204   8.777145   8.810669   8.767563   \n",
       "2      8.772354   8.777145   8.796295   8.801086   8.805878   8.772354   \n",
       "3      8.767563   8.757996   8.757996   8.757996   8.767563   8.791504   \n",
       "4      8.781937   8.781937   8.805878   8.781937   8.762772   8.757996   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "5819  11.247955   3.294418  -5.956772  -6.038177  11.578354  21.950043   \n",
       "5820  -6.746857  -2.638412   9.390060   6.876144  15.078690  15.078690   \n",
       "5821   9.495407 -14.068329 -19.512741 -11.065994   2.049438   2.049438   \n",
       "5822  11.903976   2.710236   5.200211  11.745956   5.736511  10.702087   \n",
       "5823  22.227768  39.446870  30.928299   7.326263   4.017471  16.634918   \n",
       "\n",
       "       Acc-Z_99  Acc-Z_100  \n",
       "0      8.781937   8.753204  \n",
       "1      8.815445   8.781937  \n",
       "2      8.796295   8.805878  \n",
       "3      8.786728   8.786728  \n",
       "4      8.762772   8.767563  \n",
       "...         ...        ...  \n",
       "5819  22.313965   7.627930  \n",
       "5820   7.762009  10.433929  \n",
       "5821  10.376465  13.273453  \n",
       "5822   2.834732   2.078171  \n",
       "5823  16.634918  20.034683  \n",
       "\n",
       "[5824 rows x 101 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/handlebar/processed_segments_overlap_20.csv') \n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose df is your DataFrame, and df['curb_scene'] is your label column\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(df, df['curb_scene'], \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling data, because neural network works better with scaled data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit(train_data.iloc[:, 1:])\n",
    "#transform data\n",
    "train_data_scaled = scaler.transform(train_data.iloc[:, 1:])\n",
    "test_data_scaled = scaler.transform(test_data.iloc[:, 1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc-Z_1</th>\n",
       "      <th>Acc-Z_2</th>\n",
       "      <th>Acc-Z_3</th>\n",
       "      <th>Acc-Z_4</th>\n",
       "      <th>Acc-Z_5</th>\n",
       "      <th>Acc-Z_6</th>\n",
       "      <th>Acc-Z_7</th>\n",
       "      <th>Acc-Z_8</th>\n",
       "      <th>Acc-Z_9</th>\n",
       "      <th>Acc-Z_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Acc-Z_92</th>\n",
       "      <th>Acc-Z_93</th>\n",
       "      <th>Acc-Z_94</th>\n",
       "      <th>Acc-Z_95</th>\n",
       "      <th>Acc-Z_96</th>\n",
       "      <th>Acc-Z_97</th>\n",
       "      <th>Acc-Z_98</th>\n",
       "      <th>Acc-Z_99</th>\n",
       "      <th>Acc-Z_100</th>\n",
       "      <th>curb_scene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.292349</td>\n",
       "      <td>-1.413383</td>\n",
       "      <td>-0.865768</td>\n",
       "      <td>0.861620</td>\n",
       "      <td>2.237443</td>\n",
       "      <td>1.867200</td>\n",
       "      <td>-0.138699</td>\n",
       "      <td>-1.420708</td>\n",
       "      <td>-1.853424</td>\n",
       "      <td>-0.999532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290532</td>\n",
       "      <td>-0.695047</td>\n",
       "      <td>0.265154</td>\n",
       "      <td>-1.114271</td>\n",
       "      <td>-0.630063</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>1.410097</td>\n",
       "      <td>1.663488</td>\n",
       "      <td>-0.010922</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.566530</td>\n",
       "      <td>0.940266</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.903194</td>\n",
       "      <td>-0.504935</td>\n",
       "      <td>-0.348031</td>\n",
       "      <td>0.035411</td>\n",
       "      <td>1.016076</td>\n",
       "      <td>-1.665892</td>\n",
       "      <td>-1.997259</td>\n",
       "      <td>...</td>\n",
       "      <td>1.926692</td>\n",
       "      <td>0.939806</td>\n",
       "      <td>0.866528</td>\n",
       "      <td>-0.761206</td>\n",
       "      <td>-1.180753</td>\n",
       "      <td>-1.141454</td>\n",
       "      <td>-2.330392</td>\n",
       "      <td>-0.885422</td>\n",
       "      <td>-0.942968</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.061578</td>\n",
       "      <td>-0.077279</td>\n",
       "      <td>-0.059848</td>\n",
       "      <td>-0.053777</td>\n",
       "      <td>-0.046199</td>\n",
       "      <td>-0.050972</td>\n",
       "      <td>-0.055789</td>\n",
       "      <td>-0.052186</td>\n",
       "      <td>-0.053610</td>\n",
       "      <td>-0.054573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058487</td>\n",
       "      <td>-0.067871</td>\n",
       "      <td>-0.070930</td>\n",
       "      <td>-0.079835</td>\n",
       "      <td>-0.069375</td>\n",
       "      <td>-0.051041</td>\n",
       "      <td>-0.036795</td>\n",
       "      <td>-0.037158</td>\n",
       "      <td>-0.060022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.069194</td>\n",
       "      <td>-0.081099</td>\n",
       "      <td>-0.067352</td>\n",
       "      <td>-0.059715</td>\n",
       "      <td>-0.052059</td>\n",
       "      <td>-0.053354</td>\n",
       "      <td>-0.060311</td>\n",
       "      <td>-0.055958</td>\n",
       "      <td>-0.060916</td>\n",
       "      <td>-0.058632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067872</td>\n",
       "      <td>-0.074871</td>\n",
       "      <td>-0.074999</td>\n",
       "      <td>-0.080634</td>\n",
       "      <td>-0.073541</td>\n",
       "      <td>-0.051860</td>\n",
       "      <td>-0.038404</td>\n",
       "      <td>-0.037982</td>\n",
       "      <td>-0.053132</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.561424</td>\n",
       "      <td>-0.763283</td>\n",
       "      <td>-0.747205</td>\n",
       "      <td>-0.149548</td>\n",
       "      <td>0.353940</td>\n",
       "      <td>-0.116896</td>\n",
       "      <td>-0.240452</td>\n",
       "      <td>-0.757572</td>\n",
       "      <td>-1.566038</td>\n",
       "      <td>-1.525592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353564</td>\n",
       "      <td>2.079568</td>\n",
       "      <td>0.842116</td>\n",
       "      <td>-1.210128</td>\n",
       "      <td>-2.416267</td>\n",
       "      <td>-1.107891</td>\n",
       "      <td>1.684010</td>\n",
       "      <td>1.111706</td>\n",
       "      <td>-0.172868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Acc-Z_1   Acc-Z_2   Acc-Z_3   Acc-Z_4   Acc-Z_5   Acc-Z_6   Acc-Z_7  \\\n",
       "0 -1.292349 -1.413383 -0.865768  0.861620  2.237443  1.867200 -0.138699   \n",
       "1 -0.566530  0.940266  0.907407  0.903194 -0.504935 -0.348031  0.035411   \n",
       "2 -0.061578 -0.077279 -0.059848 -0.053777 -0.046199 -0.050972 -0.055789   \n",
       "3 -0.069194 -0.081099 -0.067352 -0.059715 -0.052059 -0.053354 -0.060311   \n",
       "4  0.561424 -0.763283 -0.747205 -0.149548  0.353940 -0.116896 -0.240452   \n",
       "\n",
       "    Acc-Z_8   Acc-Z_9  Acc-Z_10  ...  Acc-Z_92  Acc-Z_93  Acc-Z_94  Acc-Z_95  \\\n",
       "0 -1.420708 -1.853424 -0.999532  ... -0.290532 -0.695047  0.265154 -1.114271   \n",
       "1  1.016076 -1.665892 -1.997259  ...  1.926692  0.939806  0.866528 -0.761206   \n",
       "2 -0.052186 -0.053610 -0.054573  ... -0.058487 -0.067871 -0.070930 -0.079835   \n",
       "3 -0.055958 -0.060916 -0.058632  ... -0.067872 -0.074871 -0.074999 -0.080634   \n",
       "4 -0.757572 -1.566038 -1.525592  ...  0.353564  2.079568  0.842116 -1.210128   \n",
       "\n",
       "   Acc-Z_96  Acc-Z_97  Acc-Z_98  Acc-Z_99  Acc-Z_100  curb_scene  \n",
       "0 -0.630063  0.001351  1.410097  1.663488  -0.010922         0.0  \n",
       "1 -1.180753 -1.141454 -2.330392 -0.885422  -0.942968         1.0  \n",
       "2 -0.069375 -0.051041 -0.036795 -0.037158  -0.060022         0.0  \n",
       "3 -0.073541 -0.051860 -0.038404 -0.037982  -0.053132         0.0  \n",
       "4 -2.416267 -1.107891  1.684010  1.111706  -0.172868         0.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the scaled data back to DataFrames for further processing\n",
    "train_data_scaled_df = pd.DataFrame(train_data_scaled, columns=train_data.columns[1:])\n",
    "test_data_scaled_df = pd.DataFrame(test_data_scaled, columns=test_data.columns[1:])\n",
    "train_data_scaled_df['curb_scene'] = train_data['curb_scene'].values\n",
    "test_data_scaled_df['curb_scene'] = test_data['curb_scene'].values\n",
    "train_data_scaled_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
      "       ...\n",
      "       1154, 1155, 1156, 1157, 1158, 1160, 1161, 1162, 1163, 1164],\n",
      "      dtype='int64', length=1123)\n",
      "Index([  76,   83,   93,  107,  148,  192,  204,  218,  256,  283,  296,  312,\n",
      "        380,  413,  417,  451,  459,  498,  501,  502,  512,  616,  682,  705,\n",
      "        709,  713,  720,  726,  735,  808,  822,  927,  970, 1007, 1023, 1042,\n",
      "       1055, 1072, 1084, 1150, 1151, 1159],\n",
      "      dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Filter and slice the data\n",
    "normal_train_data_scaled = train_data_scaled_df[train_data_scaled_df['curb_scene'] == 0.0].iloc[:, :-1]\n",
    "abnormal_train_data_scaled = train_data_scaled_df[train_data_scaled_df['curb_scene'] == 1.0].iloc[:, :-1]\n",
    "normal_test_data_scaled = test_data_scaled_df[test_data_scaled_df['curb_scene'] == 0.0].iloc[:, :-1]\n",
    "abnormal_test_data_scaled = test_data_scaled_df[test_data_scaled_df['curb_scene'] == 1.0].iloc[:, :-1]\n",
    "# Example usage: Accessing the original index\n",
    "print(normal_test_data_scaled.index)\n",
    "print(abnormal_test_data_scaled.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float32\n",
    "normal_train_data_scaled = normal_train_data_scaled.astype(\"float32\")\n",
    "abnormal_train_data_scaled = abnormal_train_data_scaled.astype(\"float32\")\n",
    "normal_test_data_scaled = normal_test_data_scaled.astype(\"float32\")\n",
    "abnormal_test_data_scaled = abnormal_test_data_scaled.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allow me to use data in different ways\n",
    "class AutoEncoder(Model):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='tanh'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(32, activation='tanh'),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='tanh'),\n",
    "            tf.keras.layers.Dropout(0.2), \n",
    "            tf.keras.layers.Dense(100, activation='tanh')\n",
    "        ])\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        #returns me a decoder object\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "model = AutoEncoder()\n",
    "#if in 2 Epochs, loss is not decreasing, stop the training\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
    "model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4817 - val_loss: 0.4148\n",
      "Epoch 2/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4056 - val_loss: 0.3769\n",
      "Epoch 3/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3711 - val_loss: 0.3563\n",
      "Epoch 4/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3553 - val_loss: 0.3430\n",
      "Epoch 5/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3431 - val_loss: 0.3329\n",
      "Epoch 6/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3345 - val_loss: 0.3248\n",
      "Epoch 7/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3194 - val_loss: 0.3182\n",
      "Epoch 8/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3197 - val_loss: 0.3125\n",
      "Epoch 9/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3070 - val_loss: 0.3076\n",
      "Epoch 10/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3017 - val_loss: 0.3034\n",
      "Epoch 11/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2986 - val_loss: 0.2995\n",
      "Epoch 12/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3038 - val_loss: 0.2964\n",
      "Epoch 13/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2947 - val_loss: 0.2931\n",
      "Epoch 14/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2897 - val_loss: 0.2902\n",
      "Epoch 15/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2819 - val_loss: 0.2874\n",
      "Epoch 16/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2835 - val_loss: 0.2850\n",
      "Epoch 17/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2768 - val_loss: 0.2828\n",
      "Epoch 18/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2789 - val_loss: 0.2806\n",
      "Epoch 19/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2804 - val_loss: 0.2787\n",
      "Epoch 20/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2803 - val_loss: 0.2769\n",
      "Epoch 21/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2675 - val_loss: 0.2753\n",
      "Epoch 22/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2695 - val_loss: 0.2736\n",
      "Epoch 23/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2688 - val_loss: 0.2720\n",
      "Epoch 24/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2666 - val_loss: 0.2708\n",
      "Epoch 25/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2649 - val_loss: 0.2694\n",
      "Epoch 26/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2586 - val_loss: 0.2682\n",
      "Epoch 27/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2597 - val_loss: 0.2671\n",
      "Epoch 28/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2621 - val_loss: 0.2660\n",
      "Epoch 29/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2620 - val_loss: 0.2650\n",
      "Epoch 30/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2634 - val_loss: 0.2640\n",
      "Epoch 31/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2500 - val_loss: 0.2633\n",
      "Epoch 32/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2548 - val_loss: 0.2627\n",
      "Epoch 33/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2572 - val_loss: 0.2620\n",
      "Epoch 34/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2574 - val_loss: 0.2612\n",
      "Epoch 35/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2549 - val_loss: 0.2605\n",
      "Epoch 36/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2553 - val_loss: 0.2601\n",
      "Epoch 37/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2484 - val_loss: 0.2595\n",
      "Epoch 38/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2476 - val_loss: 0.2591\n",
      "Epoch 39/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2526 - val_loss: 0.2586\n",
      "Epoch 40/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2578 - val_loss: 0.2582\n",
      "Epoch 41/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2508 - val_loss: 0.2576\n",
      "Epoch 42/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2492 - val_loss: 0.2571\n",
      "Epoch 43/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2498 - val_loss: 0.2569\n",
      "Epoch 44/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2510 - val_loss: 0.2563\n",
      "Epoch 45/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2478 - val_loss: 0.2563\n",
      "Epoch 46/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2501 - val_loss: 0.2560\n",
      "Epoch 47/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2478 - val_loss: 0.2555\n",
      "Epoch 48/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2465 - val_loss: 0.2554\n",
      "Epoch 49/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2503 - val_loss: 0.2549\n",
      "Epoch 50/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2472 - val_loss: 0.2547\n",
      "Epoch 51/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2493 - val_loss: 0.2543\n",
      "Epoch 52/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2481 - val_loss: 0.2546\n",
      "Epoch 53/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2461 - val_loss: 0.2541\n",
      "Epoch 54/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2491 - val_loss: 0.2539\n",
      "Epoch 55/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2488 - val_loss: 0.2536\n",
      "Epoch 56/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2442 - val_loss: 0.2536\n",
      "Epoch 57/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2512 - val_loss: 0.2533\n",
      "Epoch 58/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2462 - val_loss: 0.2532\n",
      "Epoch 59/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2481 - val_loss: 0.2529\n",
      "Epoch 60/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2525 - val_loss: 0.2528\n",
      "Epoch 61/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2498 - val_loss: 0.2526\n",
      "Epoch 62/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2480 - val_loss: 0.2525\n",
      "Epoch 63/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2497 - val_loss: 0.2523\n",
      "Epoch 64/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2473 - val_loss: 0.2524\n",
      "Epoch 65/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2444 - val_loss: 0.2521\n",
      "Epoch 66/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2487 - val_loss: 0.2519\n",
      "Epoch 67/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2434 - val_loss: 0.2519\n",
      "Epoch 68/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2473 - val_loss: 0.2516\n",
      "Epoch 69/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2456 - val_loss: 0.2516\n",
      "Epoch 70/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2477 - val_loss: 0.2517\n",
      "Epoch 71/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2495 - val_loss: 0.2516\n",
      "Epoch 72/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2421 - val_loss: 0.2515\n",
      "Epoch 73/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2408 - val_loss: 0.2513\n",
      "Epoch 74/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2483 - val_loss: 0.2513\n",
      "Epoch 75/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2423 - val_loss: 0.2510\n",
      "Epoch 76/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2455 - val_loss: 0.2511\n",
      "Epoch 77/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2394 - val_loss: 0.2510\n",
      "Epoch 78/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2437 - val_loss: 0.2508\n",
      "Epoch 79/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2477 - val_loss: 0.2509\n",
      "Epoch 80/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2454 - val_loss: 0.2508\n",
      "Epoch 81/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2465 - val_loss: 0.2506\n",
      "Epoch 82/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2410 - val_loss: 0.2507\n",
      "Epoch 83/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2447 - val_loss: 0.2507\n",
      "Epoch 84/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2435 - val_loss: 0.2506\n",
      "Epoch 85/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2525 - val_loss: 0.2505\n",
      "Epoch 86/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2415 - val_loss: 0.2503\n",
      "Epoch 87/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2433 - val_loss: 0.2503\n",
      "Epoch 88/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2472 - val_loss: 0.2504\n",
      "Epoch 89/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2401 - val_loss: 0.2502\n",
      "Epoch 90/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2447 - val_loss: 0.2502\n",
      "Epoch 91/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2498 - val_loss: 0.2502\n",
      "Epoch 92/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2408 - val_loss: 0.2500\n",
      "Epoch 93/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2450 - val_loss: 0.2501\n",
      "Epoch 94/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2421 - val_loss: 0.2498\n",
      "Epoch 95/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2381 - val_loss: 0.2501\n",
      "Epoch 96/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2430 - val_loss: 0.2498\n",
      "Epoch 97/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2441 - val_loss: 0.2496\n",
      "Epoch 98/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2445 - val_loss: 0.2499\n",
      "Epoch 99/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2427 - val_loss: 0.2497\n",
      "Epoch 100/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2462 - val_loss: 0.2497\n",
      "Epoch 101/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2383 - val_loss: 0.2495\n",
      "Epoch 102/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2483 - val_loss: 0.2498\n",
      "Epoch 103/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2414 - val_loss: 0.2495\n",
      "Epoch 104/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2420 - val_loss: 0.2495\n",
      "Epoch 105/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2449 - val_loss: 0.2493\n",
      "Epoch 106/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2440 - val_loss: 0.2495\n",
      "Epoch 107/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2421 - val_loss: 0.2493\n",
      "Epoch 108/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2407 - val_loss: 0.2494\n",
      "Epoch 109/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2481 - val_loss: 0.2493\n",
      "Epoch 110/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2466 - val_loss: 0.2492\n",
      "Epoch 111/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2425 - val_loss: 0.2493\n",
      "Epoch 112/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2416 - val_loss: 0.2491\n",
      "Epoch 113/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2423 - val_loss: 0.2492\n",
      "Epoch 114/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2425 - val_loss: 0.2493\n",
      "Epoch 115/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2465 - val_loss: 0.2491\n",
      "Epoch 116/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2371 - val_loss: 0.2490\n",
      "Epoch 117/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2435 - val_loss: 0.2491\n",
      "Epoch 118/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2452 - val_loss: 0.2491\n",
      "Epoch 119/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2435 - val_loss: 0.2489\n",
      "Epoch 120/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2388 - val_loss: 0.2489\n",
      "Epoch 121/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2424 - val_loss: 0.2491\n",
      "Epoch 122/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2444 - val_loss: 0.2489\n",
      "Epoch 123/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2428 - val_loss: 0.2488\n",
      "Epoch 124/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2414 - val_loss: 0.2488\n",
      "Epoch 125/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2457 - val_loss: 0.2488\n",
      "Epoch 126/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2381 - val_loss: 0.2489\n",
      "Epoch 127/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2427 - val_loss: 0.2487\n",
      "Epoch 128/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2408 - val_loss: 0.2487\n",
      "Epoch 129/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2397 - val_loss: 0.2488\n",
      "Epoch 130/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2451 - val_loss: 0.2488\n",
      "Epoch 131/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2383 - val_loss: 0.2486\n",
      "Epoch 132/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2465 - val_loss: 0.2487\n",
      "Epoch 133/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2452 - val_loss: 0.2487\n",
      "Epoch 134/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2410 - val_loss: 0.2486\n",
      "Epoch 135/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2419 - val_loss: 0.2486\n",
      "Epoch 136/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2416 - val_loss: 0.2483\n",
      "Epoch 137/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2438 - val_loss: 0.2486\n",
      "Epoch 138/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2458 - val_loss: 0.2485\n",
      "Epoch 139/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2423 - val_loss: 0.2485\n",
      "Epoch 140/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2451 - val_loss: 0.2487\n",
      "Epoch 141/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2408 - val_loss: 0.2484\n",
      "Epoch 142/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2416 - val_loss: 0.2484\n",
      "Epoch 143/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2339 - val_loss: 0.2484\n",
      "Epoch 144/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2409 - val_loss: 0.2486\n",
      "Epoch 145/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2433 - val_loss: 0.2484\n",
      "Epoch 146/150\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2466 - val_loss: 0.2486\n"
     ]
    }
   ],
   "source": [
    "# seprate class as well for normal and abnormal data invalidation data\n",
    "history = model.fit(normal_train_data_scaled, \n",
    "                    normal_train_data_scaled,\n",
    "                    epochs=150, \n",
    "                    batch_size=128,\n",
    "                    validation_split=0.3, \n",
    "                    shuffle=True, \n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c69b5bf8f0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
